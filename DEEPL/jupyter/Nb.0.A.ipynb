{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9be86ea",
   "metadata": {},
   "source": [
    "# Introduction to PyTorch tensors (and a bit of linear algebra)\n",
    "This small notebook serves two purposes: an itroduction into Jupyter notebooks and inot PyTorch. By now you should have installed the provided Conda environment or have set up your own. If you have not started the notebook and are just reading this on the screen, do the following. \n",
    "\n",
    "1) activate the conda environment: \n",
    "<br> <center>\n",
    "    **conda activate ai_lecture**\n",
    "</center>\n",
    "\n",
    "2) change into the folder where your notbook is located and call: \n",
    "<br> <center>\n",
    "    **jupyter notebook**\n",
    "</center>\n",
    "\n",
    "A browser window should open and you shouls see this notebook\n",
    "\n",
    "<br>\n",
    "\n",
    "First, we will import pytorch and additional libraries for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad645e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib notebook\n",
    "sns.set_theme()\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ee87e4",
   "metadata": {},
   "source": [
    "The main object we will work with is torch.Tensor. As already mentioned in the lecture slides, even if we call them tensors, mathematically they are not tensors but multidimensional arrays. There are multiple constructors. Blow we will create some tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d177c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty tensor \n",
    "x1 = torch.Tensor(10)\n",
    "print(x1)\n",
    "print(f'dim(x1) = {x1.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674d0f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty tensor \n",
    "x2 = torch.empty(10)\n",
    "print(x2)\n",
    "print(f'dim(x2) = {x2.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54188139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty tensor \n",
    "x3 = torch.Tensor(3,3)\n",
    "print(x3)\n",
    "print(f'dim(x3) = {x3.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8818b216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create empty tensor \n",
    "x4 = torch.Tensor((3,3))\n",
    "print(x4)\n",
    "print(f'dim(x4) = {x4.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaa8059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create zero tensor \n",
    "x5 = torch.zeros(3,3)\n",
    "print(x5)\n",
    "print(f'dim(x5) = {x5.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcaf12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tensor filled with ones\n",
    "x6 = torch.ones(3,3)\n",
    "print(x6)\n",
    "print(f'dim(x6) = {x6.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19657804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create integer tensor filled with ones \n",
    "x7 = torch.ones(3,3, dtype=int)\n",
    "print(x7)\n",
    "print(f'dim(x7) = {x7.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9ceeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create integer tensor \n",
    "x8 = torch.ones(2,3).int()\n",
    "print(x8)\n",
    "print(f'dim(x8) = {x8.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855b1af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create integer tensor \n",
    "x9 = torch.ones(2,3,4).long()\n",
    "print(x9)\n",
    "print(f'dim(x9) = {x9.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddae3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a R^2x2x2x2 tensor filled with 2 \n",
    "x10 = torch.ones(2,2,2,2)*2\n",
    "print(x10)\n",
    "print(f'dim(x10) = {x10.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e03143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init tensor via lists \n",
    "x11 = torch.tensor([[1,2,3],[4,5,6]])\n",
    "print(x11)\n",
    "print(f'dim(x11) = {x11.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caefb99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init tensor via range\n",
    "x12 = torch.tensor(range(5))\n",
    "print(x12)\n",
    "print(f'dim(x12) = {x12.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51195e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init tensor via arange\n",
    "x13 = torch.arange(5)\n",
    "print(x13)\n",
    "print(f'dim(x13) = {x13.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e15e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init uniform random tensor\n",
    "x14 = torch.rand(3,3)\n",
    "print(x14)\n",
    "print(f'dim(x14) = {x14.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f872a027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init normal distributed random tensor\n",
    "x15 = torch.randn(3,3)\n",
    "print(x15)\n",
    "print(f'dim(x15) = {x15.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f5286c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change view of tensor\n",
    "x16 = torch.arange(10)\n",
    "print(x16)\n",
    "print(f'dim(x16) = {x16.shape}')\n",
    "x16_ = x16.view(2,5)\n",
    "print(x16_)\n",
    "print(f'dim(x16) = {x16_.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9243ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change view of tensor \n",
    "x17 = torch.arange(10)\n",
    "print(x17)\n",
    "print(f'dim(x17) = {x17.shape}')\n",
    "x17_ = x17.view(2,-1)\n",
    "print(x17_)\n",
    "print(f'dim(x17) = {x17_.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7719fac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape tensor\n",
    "x18 = torch.arange(10)\n",
    "print(x18)\n",
    "print(f'dim(x18) = {x18.shape}')\n",
    "x18_ = x18.reshape(2,-1)\n",
    "print(x18_)\n",
    "print(f'dim(x18) = {x18_.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208ad83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# above we have seen that \"=\" asigns a reference\n",
    "# can we also create a copy?\n",
    "x19 = torch.rand(2,2)\n",
    "print(x19)\n",
    "x19_ = x19.clone()\n",
    "x19_[0,0] = -1.\n",
    "print(x19)\n",
    "print(x19_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831a5f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing: we have already seen that we can index via []\n",
    "# e.g.\n",
    "x20 = torch.rand(2,2)\n",
    "print(x20)\n",
    "print(\"\\nindex element 0,0:\")\n",
    "print(x20[0,0])\n",
    "print(\"\\nget first column:\")\n",
    "print(x20[:,0])\n",
    "print(\"\\nget first row:\")\n",
    "print(x20[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718b0e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexing: we call also assign values\n",
    "print(\"\\nset element 0,0:\")\n",
    "x20[0,0] = -5\n",
    "print(x20)\n",
    "print(\"\\nset first column:\")\n",
    "x20[:,0] = 5\n",
    "print(x20)\n",
    "print(\"\\nset first row:\")\n",
    "x20[0,:] = -3\n",
    "print(x20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47d0bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare elements\n",
    "x21 = torch.rand(5,5)\n",
    "print('create random matrix:')\n",
    "print(x21)\n",
    "x21_geq = x21 > 0.5\n",
    "print('\\nelements >= 0.5:')\n",
    "print(x21_geq)\n",
    "print(\"\\ncan be used for indexing:\")\n",
    "print(x21[x21_geq])\n",
    "print(\"\\nor for assinging values:\")\n",
    "x21[x21_geq] = 0.0\n",
    "print(x21)\n",
    "print(\"\\nwe can performe the same directly:\")\n",
    "x21[x21 == 0.0] = 1.0\n",
    "print(x21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c52d491",
   "metadata": {},
   "source": [
    "Vector product between two vectors $\\boldsymbol{v}$, $\\boldsymbol{w} \\in \\mathbb{R}^d$:\n",
    "1) element wise\n",
    "\n",
    "<br><center>\n",
    "    $\\boldsymbol{u} = \n",
    "    \\boldsymbol{v} \\odot \\boldsymbol{w} =  \n",
    "    \\begin{bmatrix}\n",
    "         v_1 \\cdot w_1  \\\\\n",
    "         \\vdots \\\\\n",
    "         v_d \\cdot w_d\n",
    "    \\end{bmatrix}$  \n",
    " \n",
    " 2) \"scalar product\" or \"inner product\": various notations\n",
    "    <br><center>\n",
    "    $ \\sum_{i=1}^d v_i \\cdot w_i   = ~ \n",
    "    < \\boldsymbol{v}, \\boldsymbol{w} > = ~\n",
    "    \\boldsymbol{v}^T \\boldsymbol{w} = ~\n",
    "    \\begin{bmatrix}\n",
    "         v_1 & \\ldots & v_d\n",
    "    \\end{bmatrix} \\cdot\n",
    "    \\begin{bmatrix}\n",
    "         w_1 \\\\ \\vdots  \\\\ w_d\n",
    "    \\end{bmatrix}$\n",
    "</center>\n",
    " \n",
    "    \n",
    "3) the \"outer product\" is defined as\n",
    "<br><center>\n",
    "    $\\boldsymbol{v} \\boldsymbol{w}^T = \n",
    "    \\begin{bmatrix}\n",
    "         v_1 \\\\ \\vdots \\\\ v_d\n",
    "    \\end{bmatrix} \\cdot\n",
    "    \\begin{bmatrix}\n",
    "         w_1 & \\ldots  & w_d\n",
    "    \\end{bmatrix}$ =\n",
    "    \\begin{bmatrix}\n",
    "         v_1 w_1 & \\ldots  & v_1 w_d \\\\\n",
    "          \\vdots & \\ddots & \\vdots \\\\\n",
    "         v_d w_1 & \\ldots & v_d w_d\n",
    "    \\end{bmatrix}$\n",
    "</center>\n",
    "    \n",
    "    \n",
    " The length of a vector in euclidian space is measured by the euclidian norm:\n",
    " <br><center>\n",
    "     $||\\boldsymbol{v}|| = \\sqrt{ \\boldsymbol{v}^T \\boldsymbol{v}} = \\sqrt{ \\sum_{i=1}^d v_i^2}$\n",
    " </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123a65e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector vector multiplication\n",
    "# elementwise\n",
    "v = torch.ones(5)*2\n",
    "w = torch.rand(5)\n",
    "print(f'v: {v}')\n",
    "print(f'w: {w}')\n",
    "u = v*w\n",
    "print(f'u: {u}')\n",
    "\n",
    "\n",
    "# sum up all elements\n",
    "s = u.sum()\n",
    "print(f's: {s}')\n",
    "\n",
    "\n",
    "# inner product: multiple options\n",
    "ip1 = v@w\n",
    "print(f'ip12: {ip1}')\n",
    "ip2 = v.dot(w)\n",
    "print(f'ip12: {ip2}')\n",
    "ip3 = v.dot(w)\n",
    "print(f'ip12: {ip3}')\n",
    "\n",
    "\n",
    "# outer product 1\n",
    "op1 = v.outer(w)\n",
    "print(f'op1: {op1}')\n",
    "\n",
    "\n",
    "# outer product 2\n",
    "op2 = v.view(-1,1) @ w.view(1,-1)\n",
    "print(f'op2: {op2}')\n",
    "\n",
    "\n",
    "# calculate the norm (length) of vector v2\n",
    "n1 = v.norm()\n",
    "print(f'n1: {n1}')\n",
    "\n",
    "\n",
    "# calculate the norm via the inner product\n",
    "n2 = (v*v).sum().sqrt()\n",
    "print(f'n2: {n2}')\n",
    "n3 = v.dot(v).sqrt()\n",
    "print(f'n3: {n3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8f452a",
   "metadata": {},
   "outputs": [],
   "source": [
    "w.outer(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a13acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating 5x5 identity matrix \n",
    "I = torch.eye(5)\n",
    "print(I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffbf302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# createing N=200 normal distributed datapointss in R^2\n",
    "X = torch.randn(2,200)\n",
    "# plot the data points\n",
    "plt.close()\n",
    "sns.scatterplot(x=X[0,:], y=X[1,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1012765",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat a new dataset by adding a vector [20,20]\n",
    "b = torch.tensor([20,20])\n",
    "X2 = X + b.view(2,1) # why do we need to change the view?\n",
    "plt.close()\n",
    "sns.scatterplot(x=X[0,:], y=X[1,:])\n",
    "sns.scatterplot(x=X2[0,:], y=X2[1,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6512d34",
   "metadata": {},
   "source": [
    "As you can see, adding a vector translates our data points. In detail, the operation is\n",
    "<br><center>\n",
    "    $X_2 = X + \\boldsymbol{b} = \\begin{bmatrix}\n",
    "                            x_{1,1} & x_{1,2} \\\\\n",
    "                            x_{2,1} & x_{2,2}\n",
    "                           \\end{bmatrix} + \n",
    "                           \\begin{bmatrix}\n",
    "                            b_1 \\\\\n",
    "                            b_2\n",
    "                           \\end{bmatrix} =\n",
    "                            \\begin{bmatrix}\n",
    "                            x_{1,1} + b_1 & x_{1,2} + b_1 \\\\\n",
    "                            x_{2,1} + b_2 & x_{2,2} + b_2\n",
    "                           \\end{bmatrix}$\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6656f375",
   "metadata": {},
   "source": [
    "Below, we will not only add a vector (i.e. translate the data points) but multiply it with a matrix beforehand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652a4357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a 2x2 diagonal matrix and adding a vector [10,10]\n",
    "W = torch.zeros(2,2)\n",
    "W[0,0] = -0.5\n",
    "W[1,1] = -6.\n",
    "print(f'W = {W}')\n",
    "# now creates a new dataset according to D3 = AD + b2\n",
    "X3 = W@X\n",
    "plt.close()\n",
    "sns.scatterplot(x=X[0,:], y=X[1,:])\n",
    "sns.scatterplot(x=X2[0,:], y=X2[1,:])\n",
    "sns.scatterplot(x=X3[0,:], y=X3[1,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d05ac7",
   "metadata": {},
   "source": [
    "The matrix we multiply our data with is $W =  \\begin{bmatrix}\n",
    "                            0.5 & 0 \\\\\n",
    "                            0 & -4\n",
    "                           \\end{bmatrix} $\n",
    "                           \n",
    "Writing it out:\n",
    "\n",
    "<br><center>\n",
    "     $ X W = \\begin{bmatrix}\n",
    "                            x_{1,1} & x_{1,2} \\\\\n",
    "                            x_{2,1} & x_{2,2}\n",
    "                           \\end{bmatrix} \n",
    "                            \\begin{bmatrix}\n",
    "                            0.5 & 0 \\\\\n",
    "                            0 & -4\n",
    "                           \\end{bmatrix}  =\n",
    "                            \\begin{bmatrix}\n",
    "                            0.5 ~ x_{1,1} & -4 ~ x_{1,2} \\\\\n",
    "                            0.5 ~ x_{2,1} & -4 ~ x_{2,2}\n",
    "                           \\end{bmatrix}$\n",
    "</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "We see that multiplying our data with a diagonal matrix scales it along the $x$ and $y$ axis. In the following cell we will add values $\\neq 0$ to the off-diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9803ac8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now creat a random 2x2 matrix that also has off diagonal entries\n",
    "# what happens if you switch the sign of the off-diagonal entries?\n",
    "W2 = torch.zeros(2,2)\n",
    "W2[0,0] = 0.5\n",
    "W2[1,1] = -4.\n",
    "W2[0,1] = 2\n",
    "W2[1,0] = -2\n",
    "print(f'W2 = {W2}')\n",
    "# now creates a new dataset according to D4 = A4 @ D + b4\n",
    "X4 = W2@X\n",
    "plt.close()\n",
    "sns.scatterplot(x=X[0,:], y=X[1,:])\n",
    "sns.scatterplot(x=X2[0,:], y=X2[1,:])\n",
    "sns.scatterplot(x=X3[0,:], y=X3[1,:])\n",
    "sns.scatterplot(x=X4[0,:], y=X4[1,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2e4e68",
   "metadata": {},
   "source": [
    "As we can see, multiplying the data with a matrix can not only scale the data, but also transforms it in other ways, e.g. rotate it.\n",
    "Do we loss information when multiplying the data with a matrix? Let's see if we can find another matrix that reverts the operation from befor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc06fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "W2inv = torch.inverse(W2)\n",
    "print(f'A4inv = {W2inv}')\n",
    "Xinv = W2inv@X4\n",
    "plt.close()\n",
    "sns.scatterplot(x=X[0,:], y=X[1,:])\n",
    "sns.scatterplot(x=X2[0,:], y=X2[1,:])\n",
    "sns.scatterplot(x=X3[0,:], y=X3[1,:])\n",
    "sns.scatterplot(x=Xinv[0,:], y=Xinv[1,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593a7a51",
   "metadata": {},
   "source": [
    "We see that we exactly recovered the old data cloude. What we have calucated above is the so called inverse matrix ${W}^{-1}$ of $W$. For any matrix $B$ to be an inverse matrix of another matrix $A$ it must be true that:\n",
    "<br><center>\n",
    "       $B A = A B = A^{-1} A = A A^{-1} = I$\n",
    "</center>\n",
    "where $I$ is the identity matrix we already know from above. We already see, that this can only be true if $A$ is a square matrix. But do all square matrices have a inverse counterpart? No! We call matrices that are not square or square without an inverse \"singular matrices\". We wont't go deeper into this topic for the moment. \n",
    "\n",
    "<br>\n",
    "\n",
    "Matrix multiplications are so called \"linear mappings\". Linear mappings are a general concept in mathematics with the following characteristics: A mapping $f$ is linear, if\n",
    "<br><center>\n",
    "       $f(x + y) = f(x) + f(y)$ and $f(\\lambda x) = \\lambda f(x)$\n",
    "<center>\n",
    "    \n",
    "For our matrix multiplication this means that if we mulitply our data $X$ with the sum of tow matrices $A + B$ or with a scalar porduct $\\lambda A$ we have\n",
    "<br><center>\n",
    "       $ (A + B)X = AX + BX$ and $\\lambda AX =  A ( \\lambda X)$\n",
    "<center>\n",
    "\n",
    "    \n",
    "All transformations that can be expressed as a matrix multiplication plus one translation are so called \"affine transformations\". The most basic neural networks (fully connected) are multiple such affine transformations stacked on ech other seperated by pointwise nonlinear functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a44f87",
   "metadata": {},
   "source": [
    " Let us apply a pointwise nonlinear function on the output of a affine transfomration of our input data. What does \"pointwise\" mean? Suppose we have a function $\\sigma: \\mathbb{R} \\rightarrow \\mathbb{R}$ and we apply it on a vector(!) $\\boldsymbol{v} \\in \\mathbb{R}^d$. What we really do is the following:\n",
    "<br><center>\n",
    "    $\\sigma(\\boldsymbol{v}) = \\begin{bmatrix}\n",
    "         \\sigma(v_1) \\\\ \\vdots  \\\\ \\sigma(v_d)\n",
    "    \\end{bmatrix}$\n",
    "</center>\n",
    "i.e. apply the function on every entry. Torch makes this very convenient. If we pass a multivariat array to a scalar valued function, torch applies this function on on every entry of the array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631e0a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "b3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6732250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f98fa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets use X and apply a affine trasnfomrmation and then a pointwise non linearity!\n",
    "W3 = torch.rand(2,2)\n",
    "b3 = torch.rand(2)\n",
    "WXb = W3@X + b3.view(-1,1)\n",
    "sX = torch.sigmoid(WXb)\n",
    "plt.close()\n",
    "sns.scatterplot(x=X[0,:], y=X[1,:])\n",
    "sns.scatterplot(x=WXb[0,:], y=WXb[1,:])\n",
    "sns.scatterplot(x=sX[0,:], y=sX[1,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1756b5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets use X and apply a pointwise non linearity!\n",
    "sX = torch.tanh(WXb)\n",
    "plt.close()\n",
    "sns.scatterplot(x=X[0,:], y=X[1,:])\n",
    "sns.scatterplot(x=WXb[0,:], y=WXb[1,:])\n",
    "sns.scatterplot(x=sX[0,:], y=sX[1,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c3cb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets use X and apply a pointwise non linearity!\n",
    "# can you guess how the function lookes like?\n",
    "sX = torch.relu(WXb)\n",
    "plt.close()\n",
    "sns.scatterplot(x=X[0,:], y=X[1,:])\n",
    "sns.scatterplot(x=WXb[0,:], y=WXb[1,:])\n",
    "sns.scatterplot(x=sX[0,:], y=sX[1,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d821e6",
   "metadata": {},
   "source": [
    "Tensors also have two important proerties: .data and .grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafc163e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X5 = torch.rand(2,2)\n",
    "print(f'X5 = {X5}')\n",
    "print(f'X5.data = {X5.data}')\n",
    "print(f'X5.grad = {X5.grad}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329ead39",
   "metadata": {},
   "source": [
    "We will see later what they are used for!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
