{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97139659-0cac-49cc-9c60-47887e181340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "import os\n",
    "import pandas\n",
    "import numpy as np\n",
    "import idx2numpy\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be00eb09-696f-47bd-a3e0-2d078084de9c",
   "metadata": {},
   "source": [
    "# Hyper Parameter selection\n",
    "\n",
    "- you know this notebook already: it is the Notebook Nb2.C\n",
    "- Here we have implemented a small conv net to train on MNIST\n",
    "- What we have not done so far is to do a proper hyper parameter search\n",
    "- this will be the goal now\n",
    "\n",
    "## TODO\n",
    "\n",
    "Adapt the notebook in the following way:\n",
    "- Currently there is no validation function - add it!\n",
    "- The main function should have as arguments: learning_rate, batch_size, activation_function\n",
    "- Crate a grid search over this paramters\n",
    "- This means: create three lists eg: learning_rates = [0.1, 0.01, 0.001], batch_size = [8, 16, 32], activation_functions = [ReLu, Elu]\n",
    "- iterate over all combinations of the above values: i.e. for the above case this means you need to train 3x3x2 models \n",
    "- in the best case you train models with the same hyper parameter settings multiple times, each with different seed - but this is not necessary here\n",
    "- Track the learning curves of: train loss, val loss, train accuracy, val accuracy\n",
    "- based on the curves: choose a model that you think is best!\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19619176-7b78-4302-8ac7-76594e7d8fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install idx2numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c8b7d99a-6fe6-48a8-aa77-25077fdbdc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A[1]\n",
    "# TODO: addapt the model such that the activation function is a parameter!\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    #def __init__(self, activationFirst, activationSecond): tried with multiple Activation funcs\n",
    "    def __init__(self, activationFunc):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         \n",
    "            nn.Conv2d(in_channels=1,\n",
    "                      out_channels=16,            \n",
    "                      kernel_size=5,              \n",
    "                      stride=1,                   \n",
    "                      padding=2),                              \n",
    "            activationFunc,                      \n",
    "            nn.MaxPool2d(kernel_size=2)   \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(16, 32, 5, 1, 2),     \n",
    "            activationFunc,                      \n",
    "            nn.MaxPool2d(2),                \n",
    "        )\n",
    "        # fully connected layer, output 10 classes\n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)\n",
    "        \n",
    "        self.is_conv = True\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1)       \n",
    "        output = self.out(x)\n",
    "        return output \n",
    "            \n",
    "    \n",
    "    def zero_init(self):\n",
    "        for p in self.parameters():\n",
    "            p.data.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf01bf8e-fc78-4dc4-bcd9-052db72a2be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_idxfile(path: str) -> np.array:\n",
    "    # can we do that for all files in the folder? \n",
    "    arr = idx2numpy.convert_from_file(path)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7829f3cf-f0e3-4e57-a487-0e54d0ab4f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: addapt the paths and load the files\n",
    "# file_path = r'/home/hubert/Lecture/data/raw/t10k-images.idx3-ubyte'\n",
    "\n",
    "notebook_path = os.path.abspath(\"A4.ipynb\")\n",
    "folder = os.path.join(os.path.dirname(notebook_path), \"idx_raw\")\n",
    "\n",
    "file_path = os.path.join(folder, \"t10k-images.idx3-ubyte\")\n",
    "data = load_idxfile(file_path)\n",
    "file_path_labels = os.path.join(folder, \"t10k-labels.idx1-ubyte\")\n",
    "labels = load_idxfile(file_path_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "32bc1cba-6eb0-4ad9-8c4e-4253d7a2951b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the data set: Nothing to do here\n",
    "class MNISTDset(Dataset):\n",
    "    def __init__(self, images: np.array, labels: np.array) -> None:\n",
    "        self.images = torch.tensor(images)/255.\n",
    "        self.labels = torch.tensor(labels)\n",
    "        self.num_samples = len(self.labels)\n",
    "        \n",
    "        # nomralize to standard deviation\n",
    "        self._normalize()\n",
    "        \n",
    "        \n",
    "    def set_num_samples(self, n:int=None) -> None:\n",
    "        '''\n",
    "        Restrict numbers of samples. \n",
    "        Not necessary, but sometimes useful for model testing \n",
    "        '''\n",
    "        if n is None:\n",
    "            self.num_samples = len(self.labels)\n",
    "        else:\n",
    "            assert 0 <=  n <= len(self.labels)\n",
    "            self.num_samples = n\n",
    "            \n",
    "    def _normalize(self, mean: float=None, std: float=None):\n",
    "        if std is not None: \n",
    "            assert std > 0\n",
    "        '''Normalize data to nomral standard'''\n",
    "        self.images = self.images - self.images.mean() if mean is None else self.images - mean \n",
    "        self.images = self.images / (self.images.std() + 1e-12) if std == None else self.images / std\n",
    "        \n",
    "    def __len__(self):\n",
    "        ret = self.num_samples\n",
    "        return ret\n",
    "    \n",
    "    def __getitem__(self, idx:int) -> Tuple[torch.Tensor, torch.Tensor, int]:\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        return image, label, idx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "315d51e8-13c2-41d6-a3d8-16573355a38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, labels):\n",
    "    return (out.argmax(-1) == label).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71794817-5e1e-424c-8d24-1fdf50768c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A[2]\n",
    "# TODO: addapt the function such that you can track the train loss and train accuracy\n",
    "# -> adjusted return to be Tuple[float,float]\n",
    "def train(model, train_loader, optimizer, loss_fun, device, epoch) -> Tuple[float, float]:\n",
    "    model.train()\n",
    "    \n",
    "    for i, (image, targets, idx) in enumerate(train_loader):\n",
    "        # get batch size\n",
    "        bs = image.shape[0]\n",
    "            \n",
    "        # fully connected model: we need to flatten the images\n",
    "        x = image.view(bs,-1) if not model.is_conv else image.view(bs,1,28,28)\n",
    "            \n",
    "        # image to device\n",
    "        x = x.to(device)\n",
    "            \n",
    "        # zero grads\n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        # forward pass\n",
    "        out = model(x)\n",
    "            \n",
    "        # calc loss and gradients\n",
    "        loss = loss_fun(out, targets).mean()\n",
    "        loss.backward()\n",
    "            \n",
    "        # update\n",
    "        optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27efd2d1-193c-4aa4-b019-0b394b920865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A[3]:\n",
    "# TODO: write the eval function - make sure you can track the eval loss and the eval accuracy!\n",
    "\n",
    "# Eric: I suppose the valid Method is meant\n",
    "\n",
    "def valid(model, test_loader, optimizer, loss_fun, device, epoch) -> Tuple[float, float]:\n",
    "    # TODO: adapt code beolow\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (image, targets, idx) in enumerate(test_loader):\n",
    "            # get batch size\n",
    "            bs = image.shape[0]\n",
    "                \n",
    "            # fully connected model: we need to flatten the images\n",
    "            x = image.view(bs,-1) if not model.is_conv else image.view(bs,1,28,28)\n",
    "                \n",
    "            # image to device\n",
    "            x = x.to(device)\n",
    "                \n",
    "            # zero grads\n",
    "            optimizer.zero_grad()\n",
    "                \n",
    "            # forward pass\n",
    "            out = model(x)\n",
    "                \n",
    "            # calc loss and gradients\n",
    "            loss = loss_fun(out, targets).mean()\n",
    "            loss.backward()\n",
    "                \n",
    "            # update\n",
    "            optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99b6f712-b5f4-49f5-a644-c3d575e0c1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data count= 10000\n",
      "80% train data split count = 8000\n",
      "actual train_data count = 6272000\n",
      "actual train_labels count = 8000\n",
      "actual val_data count= 1568000\n",
      "actual val_labels count = 2000\n"
     ]
    }
   ],
   "source": [
    "# A[4]: Choose a reasonable split (i.e. size of the splits)\n",
    "# Justify your choice!\n",
    "# we split the data into train and validation dataset and create two dataloader objects\n",
    "\n",
    "# its common to use a 80/20% split for train and validation data size - this\n",
    "# was recommanded to us by lecturers.\n",
    "dataCount = len(data)\n",
    "print(\"data count=\", dataCount)\n",
    "\n",
    "dataTrainCount = (int) (dataCount * 0.8)\n",
    "print(\"80% train data split count =\", dataTrainCount)\n",
    "\n",
    "# training data\n",
    "train_data = data[:dataTrainCount] # this will take a subset of the data till the 80% size of the numpy array\n",
    "train_labels = labels[:dataTrainCount] # same for labels\n",
    "train_dset = MNISTDset(images=train_data, labels=train_labels)\n",
    "train_loader = DataLoader(dataset=train_dset, batch_size=8, shuffle=True, num_workers=0)\n",
    "\n",
    "print(\"actual train_data count =\", train_data.size)\n",
    "print(\"actual train_labels count =\", train_labels.size)\n",
    "\n",
    "# val data\n",
    "val_data = data[dataTrainCount:] # takes the last 20% of the numpy array as validation set\n",
    "val_labels = labels[dataTrainCount:] # same for labels\n",
    "val_dset = MNISTDset(images=val_data, labels=val_labels)\n",
    "val_loader = DataLoader(dataset=val_dset, batch_size=8, shuffle=False, num_workers=0)\n",
    "\n",
    "print(\"actual val_data count=\", val_data.size)\n",
    "print(\"actual val_labels count =\", val_labels.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5bc4219c-b4af-46a8-9a9b-6cf2a4491644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A[5]-A[10]: \n",
    "# - Adapt the main loop like described above: it should have three arguments: learning rates, batch size and activation functions \n",
    "# - iterate over all combinations of the hyper parameters \n",
    "# - init everything that is necessary to train the model and: train a model for each combination\n",
    "# - track the learning curves for all combinations - the main function should return the all learning curves for all combinations \n",
    "# - plot all learning curves for every trained model and choose the one you think is best\n",
    "# - justify your choice\n",
    "# implement main loop \n",
    "from audioop import avg\n",
    "\n",
    "\n",
    "def main( learning_rates:list, batch_sizes:list, activation_functions:list):\n",
    "    num_epochs = 20\n",
    "    bestModel = None\n",
    "    bestAcc = 0\n",
    "    for activFunc in activation_functions:\n",
    "        for batchSize in batch_sizes:\n",
    "            for learningRate in learning_rates:                \n",
    "                model = CNN(activFunc)\n",
    "                model.zero_init()\n",
    "                print(model)\n",
    "                optimizer = optim.Adam(params=model.parameters(),lr=learningRate)\n",
    "                ce_loss = CrossEntropyLoss()\n",
    "\n",
    "                device = 'cpu'\n",
    "                model = model.to(device)\n",
    "\n",
    "                tr_loss = []\n",
    "                tr_acc = []\n",
    "                ev_loss = []\n",
    "                ev_acc = []\n",
    "                for epoch in range(num_epochs):\n",
    "                    loss = train(model, train_loader, optimizer, ce_loss, device, epoch)\n",
    "                    tr_loss.append(loss)\n",
    "\n",
    "\n",
    "                    # calculate accuracy\n",
    "                    model.train()\n",
    "                    N = batchSize\n",
    "                    x, label, idx = train_dset[:N] \n",
    "                    x = x.view(N,1,28,28) if model.is_conv else  x.view(N,-1) \n",
    "                    out = model(x)\n",
    "                    acc_ = (out.argmax(-1) == label).float().sum()/len(label)\n",
    "                    tr_acc.append(acc_)\n",
    "\n",
    "\n",
    "                    x, label, idx = val_dset[:N] \n",
    "                    x = x.view(N,1,28,28) if model.is_conv else  x.view(N,-1)\n",
    "                    model.eval()\n",
    "                    out = model(x)\n",
    "                    acc_ = (out.argmax(-1) == label).float().sum()/len(label)\n",
    "                    ev_acc.append(acc_)\n",
    "\n",
    "\n",
    "                    print(f'epoch [{epoch+1}/{num_epochs}]: train loss = {loss:.5f}, train acc = {tr_acc[-1]:.5f}, val acc = {ev_acc[-1]:.5f}')\n",
    "\n",
    "                plt.plot(tr_loss, label='train loss')\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "\n",
    "                plt.plot(tr_acc, label='train accuracy')\n",
    "                plt.plot(ev_acc, label='eval accuracy')\n",
    "                \n",
    "                hihgest_acc = sum(ev_acc) / len(ev_acc)\n",
    "                # remember best model\n",
    "                if(hihgest_acc > bestAcc):\n",
    "                    print(f'this Model is better than best so far. Old eval acc: {bestAcc}, this eval acc: {ev_acc}')\n",
    "                    bestAcc = hihgest_acc\n",
    "                    bestModel = model\n",
    "                \n",
    "                plt.title('acc')\n",
    "                plt.legend()\n",
    "                plt.show()\n",
    "    return bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57667497-c3f8-40e2-bc50-72c935e02322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (conv1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (out): Linear(in_features=1568, out_features=10, bias=True)\n",
      ")\n",
      "epoch [1/20]: train loss = 2.32686, train acc = 0.12500, val acc = 0.12500\n",
      "epoch [2/20]: train loss = 2.35181, train acc = 0.12500, val acc = 0.00000\n",
      "epoch [3/20]: train loss = 2.18439, train acc = 0.25000, val acc = 0.25000\n",
      "epoch [4/20]: train loss = 2.23618, train acc = 0.25000, val acc = 0.12500\n",
      "epoch [5/20]: train loss = 2.37758, train acc = 0.12500, val acc = 0.37500\n",
      "epoch [6/20]: train loss = 2.37088, train acc = 0.00000, val acc = 0.00000\n",
      "epoch [7/20]: train loss = 2.32817, train acc = 0.00000, val acc = 0.00000\n",
      "epoch [8/20]: train loss = 2.25035, train acc = 0.25000, val acc = 0.25000\n",
      "epoch [9/20]: train loss = 2.38656, train acc = 0.00000, val acc = 0.00000\n",
      "epoch [10/20]: train loss = 2.36857, train acc = 0.12500, val acc = 0.12500\n",
      "epoch [11/20]: train loss = 2.28698, train acc = 0.00000, val acc = 0.00000\n",
      "epoch [12/20]: train loss = 2.38280, train acc = 0.12500, val acc = 0.00000\n",
      "epoch [13/20]: train loss = 2.38822, train acc = 0.12500, val acc = 0.12500\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [26], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m batch_size \u001b[39m=\u001b[39m [\u001b[39m8\u001b[39m, \u001b[39m16\u001b[39m, \u001b[39m32\u001b[39m]\n\u001b[0;32m      3\u001b[0m activation_functions \u001b[39m=\u001b[39m [nn\u001b[39m.\u001b[39mReLU(), nn\u001b[39m.\u001b[39mELU()]\n\u001b[1;32m----> 5\u001b[0m model \u001b[39m=\u001b[39m main(learning_rates, batch_size, activation_functions)\n",
      "Cell \u001b[1;32mIn [25], line 33\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(learning_rates, batch_sizes, activation_functions)\u001b[0m\n\u001b[0;32m     31\u001b[0m ev_acc \u001b[39m=\u001b[39m []\n\u001b[0;32m     32\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[1;32m---> 33\u001b[0m     loss \u001b[39m=\u001b[39m train(model, train_loader, optimizer, ce_loss, device, epoch)\n\u001b[0;32m     34\u001b[0m     tr_loss\u001b[39m.\u001b[39mappend(loss)\n\u001b[0;32m     37\u001b[0m     \u001b[39m# calculate accuracy\u001b[39;00m\n",
      "Cell \u001b[1;32mIn [20], line 25\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_loader, optimizer, loss_fun, device, epoch)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39m# calc loss and gradients\u001b[39;00m\n\u001b[0;32m     24\u001b[0m loss \u001b[39m=\u001b[39m loss_fun(out, targets)\u001b[39m.\u001b[39mmean()\n\u001b[1;32m---> 25\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     27\u001b[0m \u001b[39m# update\u001b[39;00m\n\u001b[0;32m     28\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n",
      "File \u001b[1;32mc:\\Users\\Eric\\miniconda3\\envs\\lecture\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Users\\Eric\\miniconda3\\envs\\lecture\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "learning_rates = [0.1, 0.01, 0.001] \n",
    "batch_size = [8, 16, 32]\n",
    "activation_functions = [nn.ReLU(), nn.ELU()]\n",
    "\n",
    "model = main(learning_rates, batch_size, activation_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d94d9e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('lecture')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "dfdd3e841bfae7d0ce1e26b4e00b5a6aed2f3fe7185f859880ab8fd14b7d0bf3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
