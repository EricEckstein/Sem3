{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97139659-0cac-49cc-9c60-47887e181340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "import os\n",
    "import pandas\n",
    "import numpy as np\n",
    "import idx2numpy\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19619176-7b78-4302-8ac7-76594e7d8fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting idx2numpy\n",
      "  Downloading idx2numpy-1.2.3.tar.gz (6.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy in c:\\users\\ericeckstein\\miniconda3\\envs\\deepl\\lib\\site-packages (from idx2numpy) (1.23.3)\n",
      "Requirement already satisfied: six in c:\\users\\ericeckstein\\miniconda3\\envs\\deepl\\lib\\site-packages (from idx2numpy) (1.16.0)\n",
      "Building wheels for collected packages: idx2numpy\n",
      "  Building wheel for idx2numpy (setup.py): started\n",
      "  Building wheel for idx2numpy (setup.py): finished with status 'done'\n",
      "  Created wheel for idx2numpy: filename=idx2numpy-1.2.3-py3-none-any.whl size=7905 sha256=45691d4862d5f9087da2419b71fa616aa3e68c8d06f71a08ea8ac44150ade13a\n",
      "  Stored in directory: c:\\users\\ericeckstein\\appdata\\local\\pip\\cache\\wheels\\34\\61\\53\\a6a64db5e907bdf792f401b5bfb922eabfe6686d08692167f3\n",
      "Successfully built idx2numpy\n",
      "Installing collected packages: idx2numpy\n",
      "Successfully installed idx2numpy-1.2.3\n"
     ]
    }
   ],
   "source": [
    "! pip install idx2numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6338563-fc1e-4d7f-9129-f374e78b7e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NonLinearModel(torch.nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim: int, \n",
    "                 n_intermediate: int,\n",
    "                 intermediate_dim: int, \n",
    "                 output_dim: int,\n",
    "                 act_fun: nn.Module) -> None:\n",
    "        super(NonLinearModel, self).__init__()\n",
    "        \n",
    "        self.is_conv = False\n",
    "        \n",
    "        # we will store all our layers/operations here\n",
    "        self.layers = torch.nn.Sequential()\n",
    "        \n",
    "        if n_intermediate > 0:  \n",
    "            # add input layer\n",
    "            self.layers.append(nn.Linear(in_features=input_dim, \n",
    "                                         out_features=intermediate_dim))\n",
    "        \n",
    "            # add intermediate layers and activation functions\n",
    "            for _ in range(n_intermediate-1):\n",
    "                self.layers.append(act_fun)\n",
    "                self.layers.append(nn.Linear(in_features=intermediate_dim, \n",
    "                                             out_features=intermediate_dim))\n",
    "        \n",
    "            # add  output layer\n",
    "            self.layers.append(act_fun)\n",
    "            self.layers.append(nn.Linear(in_features=intermediate_dim, \n",
    "                                         out_features=output_dim))\n",
    "        else:\n",
    "            self.layers.append(nn.Linear(in_features=input_dim, \n",
    "                                         out_features=output_dim))\n",
    "            \n",
    "            \n",
    "    # TODO: addapt output: we have 10 classes! use softmax or do we? \n",
    "    # lets investigate the cross netropy loss and NLLLOSS\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # execute all operations\n",
    "        out = self.layers(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8b7d99a-6fe6-48a8-aa77-25077fdbdc4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         \n",
    "            nn.Conv2d(in_channels=1,\n",
    "                      out_channels=16,            \n",
    "                      kernel_size=5,              \n",
    "                      stride=1,                   \n",
    "                      padding=2),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(kernel_size=2),    \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(16, 32, 5, 1, 2),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2),                \n",
    "        )\n",
    "        # fully connected layer, output 10 classes\n",
    "        self.out = nn.Linear(32 * 7 * 7, 10)\n",
    "        \n",
    "        self.is_conv = True\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1)       \n",
    "        output = self.out(x)\n",
    "        return output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "111612c0-8ef1-4df3-9243-0dd941ee3d3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([42310])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = NonLinearModel(input_dim=28*28, n_intermediate=2, intermediate_dim=50, act_fun=nn.ReLU(), output_dim=10)\n",
    "torch.nn.utils.parameters_to_vector(net.parameters()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00d0b6ad-8186-4413-9a3f-6d725cce52f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28938])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn = CNN()\n",
    "torch.nn.utils.parameters_to_vector(cnn.parameters()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf01bf8e-fc78-4dc4-bcd9-052db72a2be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_idxfile(path: str) -> np.array:\n",
    "    # can we do that for all files in the folder? \n",
    "    arr = idx2numpy.convert_from_file(path)\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7829f3cf-f0e3-4e57-a487-0e54d0ab4f33",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/hubert/Lecture/data/raw/t10k-images.idx3-ubyte'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [11], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/hubert/Lecture/data/raw/t10k-images.idx3-ubyte\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#file_path = r'/path/to/t10k-images.idx3-ubyte'\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mload_idxfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [10], line 3\u001b[0m, in \u001b[0;36mload_idxfile\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_idxfile\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39marray:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# can we do that for all files in the folder? \u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43midx2numpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\deepl\\lib\\site-packages\\idx2numpy\\converters.py:56\u001b[0m, in \u001b[0;36mconvert_from_file\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;124;03mReads the content of file in IDX format, converts it into numpy.ndarray and\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03mreturns it.\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03mfile is a file-like object (with read() method) or a file name.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(file, six_string_types):\n\u001b[1;32m---> 56\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     57\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _internal_convert(f)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/hubert/Lecture/data/raw/t10k-images.idx3-ubyte'"
     ]
    }
   ],
   "source": [
    "file_path = r'/home/hubert/Lecture/data/raw/t10k-images.idx3-ubyte'\n",
    "#file_path = r'/path/to/t10k-images.idx3-ubyte'\n",
    "data = load_idxfile(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2ca4734-0b67-4925-9303-54539445d668",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/hubert/Lecture/data/raw/t10k-labels.idx1-ubyte'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [12], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m file_path_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/hubert/Lecture/data/raw/t10k-labels.idx1-ubyte\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m#file_path = r'/path/to/t10k-labels.idx1-ubyte'\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43mload_idxfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path_labels\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [10], line 3\u001b[0m, in \u001b[0;36mload_idxfile\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_idxfile\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39marray:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;66;03m# can we do that for all files in the folder? \u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43midx2numpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\deepl\\lib\\site-packages\\idx2numpy\\converters.py:56\u001b[0m, in \u001b[0;36mconvert_from_file\u001b[1;34m(file)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;124;03mReads the content of file in IDX format, converts it into numpy.ndarray and\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;124;03mreturns it.\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03mfile is a file-like object (with read() method) or a file name.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(file, six_string_types):\n\u001b[1;32m---> 56\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m     57\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _internal_convert(f)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/hubert/Lecture/data/raw/t10k-labels.idx1-ubyte'"
     ]
    }
   ],
   "source": [
    "file_path_labels = r'/home/hubert/Lecture/data/raw/t10k-labels.idx1-ubyte'\n",
    "#file_path = r'/path/to/t10k-labels.idx1-ubyte'\n",
    "labels = load_idxfile(file_path_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe1decb-1198-4546-969e-db09ffce666a",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "print(f'Label: {labels[idx]}')\n",
    "plt.imshow(data[idx])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bc1cba-6eb0-4ad9-8c4e-4253d7a2951b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDset(Dataset):\n",
    "    def __init__(self, images: np.array, labels: np.array) -> None:\n",
    "        self.images = torch.tensor(images)/255.\n",
    "        self.labels = torch.tensor(labels)\n",
    "        self.num_samples = len(self.labels)\n",
    "        \n",
    "        # nomralize to standard deviation\n",
    "        self._normalize()\n",
    "        \n",
    "        \n",
    "    def set_num_samples(self, n:int=None) -> None:\n",
    "        '''\n",
    "        Restrict numbers of samples. \n",
    "        Not necessary, but sometimes useful for model testing \n",
    "        '''\n",
    "        if n is None:\n",
    "            self.num_samples = len(self.labels)\n",
    "        else:\n",
    "            assert 0 <=  n <= len(self.labels)\n",
    "            self.num_samples = n\n",
    "            \n",
    "    def _normalize(self, mean: float=None, std: float=None):\n",
    "        if std is not None: \n",
    "            assert std > 0\n",
    "        '''Normalize data to nomral standard'''\n",
    "        self.images = self.images - self.images.mean() if mean is None else self.images - mean \n",
    "        self.images = self.images / (self.images.std() + 1e-12) if std == None else self.images / std\n",
    "        \n",
    "    def __len__(self):\n",
    "        ret = self.num_samples\n",
    "        return ret\n",
    "    \n",
    "    def __getitem__(self, idx:int) -> Tuple[torch.Tensor, torch.Tensor, int]:\n",
    "        image = self.images[idx]\n",
    "        label = self.labels[idx]\n",
    "        return image, label, idx "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7df5f2-923f-4547-b0c4-c600c6985a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = MNISTDset(images=data, labels=labels)\n",
    "print(f'num samples in dataset: {len(dset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae49262b-ed4c-4255-b346-92dc42b87d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label, idx = dset[15]\n",
    "print(f'Label = {label}')\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dc8c87-36cd-4b60-beff-d1b6627c42be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dloader = DataLoader(dset, batch_size=10, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ff3ffd-c21d-4fe6-b993-5d99acc5ed21",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (image, targets, idx) in enumerate(dloader):\n",
    "    print(image.shape)\n",
    "    print(targets)\n",
    "    print(idx)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "315d51e8-13c2-41d6-a3d8-16573355a38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(out, labels):\n",
    "    return (out.argmax(-1) == label).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71794817-5e1e-424c-8d24-1fdf50768c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, loss_fun, device, epoch) -> Tuple[float, float]:\n",
    "    model.train()\n",
    "    \n",
    "    n_batches = len(train_loader)\n",
    "    for i, (image, targets, idx) in enumerate(train_loader):\n",
    "        # get batch size\n",
    "        bs = image.shape[0]\n",
    "            \n",
    "        # fully connected model: we need to flatten the images\n",
    "        x = image.view(bs,-1) if not model.is_conv else image.view(bs,1,28,28)\n",
    "            \n",
    "        # image to device\n",
    "        x = x.to(device)\n",
    "            \n",
    "        # zero grads\n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        # forward pass\n",
    "        out = model(x)\n",
    "            \n",
    "        # calc loss and gradients\n",
    "        loss = loss_fun(out, targets).mean()\n",
    "        loss.backward()\n",
    "            \n",
    "        # update\n",
    "        optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b6f712-b5f4-49f5-a644-c3d575e0c1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we split the data into train and validation dataset and create two dataloader objects\n",
    "\n",
    "# training data\n",
    "train_data = data[:8000]\n",
    "train_labels = labels[:8000]\n",
    "\n",
    "print(train_data.size)\n",
    "print(train_labels.size)\n",
    "train_dset = MNISTDset(images=train_data, labels=train_labels)\n",
    "train_loader = DataLoader(dataset=train_dset, batch_size=8, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "# val data\n",
    "val_data = data[8000:]\n",
    "val_labels = labels[8000:]\n",
    "val_dset = MNISTDset(images=val_data, labels=val_labels)\n",
    "val_loader = DataLoader(dataset=val_dset, batch_size=8, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc4219c-b4af-46a8-9a9b-6cf2a4491644",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement main loop \n",
    "def main():\n",
    "    num_epochs = 20\n",
    "    model = NonLinearModel(input_dim=28*28, n_intermediate=2, intermediate_dim=50, act_fun=nn.ReLU(), output_dim=10)\n",
    "    #model = CNN()\n",
    "    print(model)\n",
    "    optimizer = optim.Adam(params=model.parameters(),lr=0.001)\n",
    "    ce_loss = CrossEntropyLoss()\n",
    "    \n",
    "    device = 'cpu'\n",
    "    model = model.to(device)\n",
    "    \n",
    "    tr_loss = []\n",
    "    tr_acc = []\n",
    "    ev_loss = []\n",
    "    ev_acc = []\n",
    "    for epoch in range(num_epochs):\n",
    "        loss = train(model, train_loader, optimizer, ce_loss, device, epoch)\n",
    "        tr_loss.append(loss)\n",
    "        \n",
    "        \n",
    "        # calculate accuracy\n",
    "        model.eval()\n",
    "        N = 2000\n",
    "        x, label, idx = train_dset[:N] \n",
    "        x = x.view(N,1,28,28) if model.is_conv else  x.view(N,-1) \n",
    "        out = model(x)\n",
    "        acc_ = (out.argmax(-1) == label).float().sum()/len(label)\n",
    "        tr_acc.append(acc_)\n",
    "\n",
    "\n",
    "        x, label, idx = val_dset[:N] \n",
    "        x = x.view(N,1,28,28) if model.is_conv else  x.view(N,-1)\n",
    "        model.eval()\n",
    "        out = model(x)\n",
    "        acc_ = (out.argmax(-1) == label).float().sum()/len(label)\n",
    "        ev_acc.append(acc_)\n",
    "        \n",
    "        \n",
    "        print(f'epoch [{epoch+1}/{num_epochs}]: train loss = {loss:.5f}, train acc = {tr_acc[-1]:.5f}, val acc = {ev_acc[-1]:.5f}')\n",
    "    \n",
    "    plt.plot(tr_loss, label='train loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    plt.plot(tr_acc, label='train accuracy')\n",
    "    plt.plot(ev_acc, label='eval accuracy')\n",
    "    plt.title('acc')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57667497-c3f8-40e2-bc50-72c935e02322",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d8637f-94db-472f-8c96-06b73d537bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d5f367-9568-46d8-9b62-576a911933d1",
   "metadata": {},
   "source": [
    "# Modelle speichern und laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0094fe-5eaf-491b-8271-c1392eb6aee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bd2b19-f92b-4c8f-b30d-456b1291adc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(st, 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f90eca8-4e3b-45ef-9e18-1f036f48e2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load('model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625fa182-e10b-4e57-b9c0-466786059987",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_new = NonLinearModel(input_dim=28*28, n_intermediate=2, intermediate_dim=50, act_fun=nn.ReLU(), output_dim=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af201853-1b67-4eed-b54a-0920011f7ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_new.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a35698-cbc4-4c81-b48c-bab81434d261",
   "metadata": {},
   "source": [
    "# Playground\n",
    "visit https://playground.tensorflow.org/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
