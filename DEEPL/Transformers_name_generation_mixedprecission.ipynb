{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2194d084-8597-432d-ba53-ee71b5efaca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting names-dataset\n",
      "  Downloading names-dataset-3.1.0.tar.gz (58.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pycountry\n",
      "  Downloading pycountry-22.3.5.tar.gz (10.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0m eta \u001b[36m0:00:01\u001b[0m36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /home/hubert/miniconda3/envs/lecture/lib/python3.9/site-packages (from pycountry->names-dataset) (62.3.4)\n",
      "Building wheels for collected packages: names-dataset, pycountry\n",
      "  Building wheel for names-dataset (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for names-dataset: filename=names_dataset-3.1.0-py3-none-any.whl size=116832757 sha256=d418d7f77af194106681b3a661c59b00f3a02f8b4c47043c0d3c9be7cab351af\n",
      "  Stored in directory: /home/hubert/.cache/pip/wheels/8b/36/2e/49513b778ca8d01a91a8cee61425d53de963b74561bfa5f561\n",
      "  Building wheel for pycountry (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycountry: filename=pycountry-22.3.5-py2.py3-none-any.whl size=10681832 sha256=e6e30ef7f0e3d1267af41b16508fdcf01b43c07577971226a18cee66fa534fb8\n",
      "  Stored in directory: /home/hubert/.cache/pip/wheels/47/15/92/e6dc85fcb0686c82e1edbcfdf80cfe4808c058813fed0baa8f\n",
      "Successfully built names-dataset pycountry\n",
      "Installing collected packages: pycountry, names-dataset\n",
      "Successfully installed names-dataset-3.1.0 pycountry-22.3.5\n"
     ]
    }
   ],
   "source": [
    "! pip install names-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94583c4c-8847-43c1-b111-b356f6da9452",
   "metadata": {},
   "outputs": [],
   "source": [
    "from names_dataset import NameDataset, NameWrapper\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb8b48a5-a2d9-42df-81d4-7cff398bb334",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NamesDs(Dataset):\n",
    "    def __init__(self, names: list, seq_len: int, lookup: dict = None) -> None:\n",
    "        letters = sorted(list(set(''.join(names).lower())))\n",
    "        self.seq_len = seq_len\n",
    "        self.names = names\n",
    "        self.start_token = 'bos'\n",
    "        self.end_token = 'eos'\n",
    "        self.padding_token = 'pad'\n",
    "        self.lookup = lookup\n",
    "        if lookup is None:\n",
    "            self.lookup = {}\n",
    "            for i in range(len(letters)):\n",
    "                self.lookup[letters[i]] = i\n",
    "            self.lookup[self.start_token] = len(letters)\n",
    "            self.lookup[self.end_token] = len(letters) + 1\n",
    "            self.lookup[self.padding_token] = len(letters) + 2\n",
    "        \n",
    "            self.idx2letter = self._idx2letter()\n",
    "        \n",
    "    \n",
    "    def _idx2letter(self) -> dict:\n",
    "        '''create lookup dictionary num --> char'''\n",
    "        return {self.lookup[k]:k for k in self.lookup}\n",
    "    \n",
    "    def num_letters(self) -> int:\n",
    "        '''dictionary lenght'''\n",
    "        return len(self.lookup)\n",
    "    \n",
    "    def get_start_token(self) -> int:\n",
    "        '''get numeric value of start token'''\n",
    "        return self.lookup[self.start_token]\n",
    "    \n",
    "    def get_end_token(self) -> int:\n",
    "        '''get numeric value of end token'''\n",
    "        return self.lookup[self.end_token]\n",
    "        \n",
    "    def get_padding_token(self) -> int:\n",
    "        '''get numeric value of padding token'''\n",
    "        return self.lookup[self.padding_token]\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        '''num of samples in dataset'''\n",
    "        return len(self.names)\n",
    "    \n",
    "    def idx2name(self, idx: torch.Tensor) -> str:\n",
    "        '''transform index array to name'''\n",
    "        ret = []\n",
    "        for i in idx:\n",
    "            if i == self.get_end_token():\n",
    "                break\n",
    "            elif i == self.get_start_token():\n",
    "                continue\n",
    "            ret.append(self.idx2letter[i.item()])\n",
    "        return ''.join(ret)\n",
    "    \n",
    "    def name2idx(self, name: str) -> torch.Tensor:\n",
    "        '''transform name to torch integer array'''\n",
    "        chars = list(name)\n",
    "        ret = [self.lookup[self.start_token]] + [self.lookup[c] for c in chars] + [self.lookup[self.end_token]]\n",
    "        assert self.seq_len >= len(ret), 'sequnce length exceeds maximal sequence length'\n",
    "        ret = ret + [self.lookup[self.padding_token]] * (self.seq_len - len(ret))  \n",
    "        ret = torch.tensor(ret).long()\n",
    "        return ret\n",
    "        \n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor]:\n",
    "        '''prepare sample'''\n",
    "        name = self.names[idx].lower()\n",
    "        ret = self.name2idx(name)\n",
    "        return ret  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18a6003f-51c2-4f4c-8411-cd225ebc340a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.4493, 0.5507, 0.0000, 0.0000],\n",
       "          [0.4294, 0.2305, 0.3401, 0.0000],\n",
       "          [0.1410, 0.3236, 0.2069, 0.3286]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.6066, 0.3934, 0.0000, 0.0000],\n",
       "          [0.3422, 0.3717, 0.2860, 0.0000],\n",
       "          [0.2469, 0.2177, 0.2052, 0.3302]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.6029, 0.3971, 0.0000, 0.0000],\n",
       "          [0.2547, 0.3413, 0.4040, 0.0000],\n",
       "          [0.3362, 0.2024, 0.2270, 0.2344]]],\n",
       "\n",
       "\n",
       "        [[[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.6391, 0.3609, 0.0000, 0.0000],\n",
       "          [0.3752, 0.3979, 0.2269, 0.0000],\n",
       "          [0.2906, 0.3045, 0.1937, 0.2112]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.3904, 0.6096, 0.0000, 0.0000],\n",
       "          [0.2909, 0.2828, 0.4263, 0.0000],\n",
       "          [0.1585, 0.2693, 0.3085, 0.2638]],\n",
       "\n",
       "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "          [0.3522, 0.6478, 0.0000, 0.0000],\n",
       "          [0.2553, 0.4465, 0.2982, 0.0000],\n",
       "          [0.2370, 0.1751, 0.1823, 0.4055]]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.rand(2,3,4,4)\n",
    "M = (torch.ones(4,4) * float(\"-inf\")).triu(1)\n",
    "A += M\n",
    "A.softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "42406996-24de-4a8c-9048-594a71fc6a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    '''config class containing arguments for transformers'''\n",
    "    def __init__(self, **kwargs):\n",
    "        self.d = 16\n",
    "        self.input_dim = 16\n",
    "        self.conditional = True\n",
    "        self.n_heads = 4\n",
    "        self.n_layers = 2\n",
    "        self.dict_size = None\n",
    "        self.out_dim = None\n",
    "        self.max_seq_len = 50\n",
    "        self._set_args(**kwargs)\n",
    "    \n",
    "    def _set_args(self, **kwargs):\n",
    "        for key, value in kwargs.items():\n",
    "            assert hasattr(self, key), f'Invalid argument: {key}'\n",
    "            setattr(self, key, value)\n",
    "        assert self.dict_size is not None, f'no value for dict_size provided! (dict_size has not default value)'\n",
    "\n",
    "        \n",
    "class SimpleSelfAttentionHead(nn.Module):\n",
    "    '''Implementation of self attention head'''\n",
    "    def __init__(self, config):\n",
    "        super(SimpleSelfAttentionHead, self).__init__()\n",
    "        \n",
    "        self.d = config.d\n",
    "        self.input_dim = config.input_dim\n",
    "        self.beta = 1./np.sqrt(self.d)\n",
    "        \n",
    "        self.mapQ = nn.Parameter(torch.empty(self.input_dim, self.d).normal_()*0.02)\n",
    "        self.mapK = nn.Parameter(torch.empty(self.input_dim, self.d).normal_()*0.02)\n",
    "        self.mapV = nn.Parameter(torch.empty(self.input_dim, self.d).normal_()*0.02)\n",
    "        \n",
    "        self.use_mask = config.conditional\n",
    "        self.mask = None\n",
    "        \n",
    "    def forward(self, X):\n",
    "        Q = X @ self.mapQ\n",
    "        K = X @ self.mapK\n",
    "        V = X @ self.mapV\n",
    "        \n",
    "        A = Q @ K.permute(0,2,1) # keep batch size at first dimension\n",
    "        A = A * self.beta\n",
    "        if self.use_mask:\n",
    "            seq_len = A.shape[-1]\n",
    "            if self.mask is None or self.mask.shape[-1] != seq_len or self.mask.device != A.device:\n",
    "                self.mask = (torch.ones(seq_len, seq_len) * float(\"-inf\")).triu(1)\n",
    "                self.mask = self.mask.to(X.device)\n",
    "            A.data += self.mask\n",
    "            \n",
    "        A = A.softmax(dim=-1)\n",
    "        \n",
    "        V = A @ V\n",
    "        return V\n",
    "        \n",
    "        \n",
    "class SimmpleMultiheadAttention(nn.Module):\n",
    "    '''Compose multiple self attention heads to multi attention head'''\n",
    "    def __init__(self, config):\n",
    "        super(SimmpleMultiheadAttention, self).__init__()\n",
    "        \n",
    "        self.n_heads = config.n_heads\n",
    "        self.heads = nn.ModuleList([SimpleSelfAttentionHead(config) for _ in range(self.n_heads)])\n",
    "        self.project = nn.Parameter(torch.empty( config.d * self.n_heads, config.input_dim).normal_()*0.02)\n",
    "        self.act = torch.nn.GELU()\n",
    "    \n",
    "    def forward(self, X):\n",
    "        heads = [ h(X) for h in self.heads]\n",
    "        heads = torch.cat(heads, dim=-1)\n",
    "        out = heads @ self.project\n",
    "        out = self.act(out)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class AttentionLayer(nn.Module):\n",
    "    '''Multi attention heads + linear layers and layer norms'''\n",
    "    def __init__(self, config):\n",
    "        super(AttentionLayer, self).__init__()\n",
    "        \n",
    "        self.feed_forward = nn.Linear(config.input_dim, config.input_dim)\n",
    "        self.layernorm1 = nn.LayerNorm(config.input_dim)\n",
    "        self.layernorm2 = nn.LayerNorm(config.input_dim)\n",
    "        self.attention = SimmpleMultiheadAttention(config)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        out = self.attention(X)\n",
    "        out = out + X\n",
    "        out = self.layernorm1(out)\n",
    "        out_f = self.feed_forward(out)\n",
    "        out = out_f + out\n",
    "        out = self.layernorm2(out)\n",
    "        return out\n",
    "        \n",
    "        \n",
    "class TransfomreEmbedding(nn.Module):\n",
    "    '''word embedding + positional encoding'''\n",
    "    def __init__(self, config):\n",
    "        super(TransfomreEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(config.dict_size, config.input_dim)\n",
    "        # TODO!\n",
    "        self.positional_encoding = nn.Parameter(torch.empty(config.max_seq_len, config.d).normal_()*0.02)\n",
    "        \n",
    "    def forward(self, idx):\n",
    "        X = self.embedding(idx)\n",
    "        X = X + self.positional_encoding\n",
    "        return X\n",
    "\n",
    "class SimpleTransformer(nn.Module):\n",
    "    '''build the model but without output head'''\n",
    "    def __init__(self, config):\n",
    "        super(SimpleTransformer, self).__init__()\n",
    "        self.dict_size = config.dict_size\n",
    "        self.embedding = TransfomreEmbedding(config)\n",
    "        self.n_layers = config.n_layers\n",
    "        self.layers = nn.ModuleList([AttentionLayer(config) for _ in range(self.n_layers)])\n",
    "    \n",
    "    def forward(self, idx):\n",
    "        X = self.embedding(idx)                                     \n",
    "        for layer in self.layers:\n",
    "            X = layer(X)\n",
    "        return X\n",
    "    \n",
    "class ManyToManyHead(nn.Module):\n",
    "    '''Output head for many to many task'''\n",
    "    def __init__(self, config):\n",
    "        super(ManyToManyHead, self).__init__()\n",
    "        self.out_layer = nn.Linear(config.input_dim, config.out_dim)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        out = self.out_layer(X)\n",
    "        return out\n",
    "\n",
    "    \n",
    "class ManyToManyTransformer(nn.Module):\n",
    "    '''Combine base model and head to many to many model'''\n",
    "    def __init__(self, config):\n",
    "        super(ManyToManyTransformer, self).__init__()\n",
    "        self.config = config\n",
    "        self.simple_transformer = SimpleTransformer(config)\n",
    "        self.out_head = ManyToManyHead(config)\n",
    "    \n",
    "    def forward(self, idx):\n",
    "        out = self.simple_transformer(idx)\n",
    "        out = self.out_head(out)\n",
    "        return out\n",
    "    \n",
    "    def generate(self, bos_idx: int, eos_idx: int, pad_idx: int, start_idx: torch.Tensor=None, max_iter: int=10, from_top_k: int=1) -> List:\n",
    "        # input/output idx\n",
    "        #input_\n",
    "        \n",
    "        # in case of initial characters (see below) we need to check if \"eos\" token is already\n",
    "        # in the sequence - in this case, we do not need any prediction\n",
    "        has_finished = False \n",
    "        \n",
    "        # if we have already some initial characters (i.e. the task is to complete a name\n",
    "        seq = (torch.ones(self.config.max_seq_len) * pad_idx).long()\n",
    "        start = None\n",
    "        if start_idx is not None:\n",
    "            seq[:len(start_idx)] = start_idx\n",
    "            start = len(start_idx)\n",
    "        else:\n",
    "            # start sequence with \"bos\" token\n",
    "            seq[0] = bos_idx\n",
    "            start = 1\n",
    "            \n",
    "        # predict (rest of) the sequence\n",
    "        for i in range(max_iter):\n",
    "            out = self(seq[None])\n",
    "            seq[start + i] = out[0,i].topk(from_top_k).indices[torch.rand(from_top_k).argmax()]\n",
    "            if seq[start + i].item() == eos_idx:\n",
    "                break\n",
    "        \n",
    "        return seq\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deb01233-ba5b-4c3d-8724-dcb1dc311e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_model_size(model):\n",
    "    param_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "    buffer_size = 0\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "\n",
    "    size_all_mb = (param_size + buffer_size) / 1024**2\n",
    "    print('model size: {:.3f}MB'.format(size_all_mb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5775031c-9a81-4831-9e4d-80da47d5093f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 0.038MB\n"
     ]
    }
   ],
   "source": [
    "config = Config(dict_size=10, out_dim=10, conditional=True)\n",
    "model = ManyToManyTransformer(config)\n",
    "print_model_size(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "031b1efd-0873-40af-aefd-2f2ae7ece641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model size: 0.019MB\n"
     ]
    }
   ],
   "source": [
    "print_model_size(model.half())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6cdd9fd-5b5c-4aa9-9ab6-484f5c03ee67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(names, p_train):\n",
    "    n_train = int(len(names) * p_train)\n",
    "    # shuffle data\n",
    "    idx = random.sample(range(len(names)), len(names))\n",
    "    train_data = [names[i] for i in idx[:n_train]]\n",
    "    val_data = [names[i] for i in idx[n_train:]]\n",
    "    return train_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aca5d0ec-8e37-4957-b5d0-29cc9da95d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " reading names from country [105/105]"
     ]
    }
   ],
   "source": [
    "# read names dataset and convert to lookup \n",
    "nd = NameDataset()\n",
    "names = []\n",
    "top_names = nd.get_top_names()\n",
    "# use all first names of all countries\n",
    "for i, countries in enumerate(top_names):\n",
    "    print(f'\\r reading names from country [{i+1}/{len(top_names)}]', end=\"\")\n",
    "    names += top_names[countries]['M']\n",
    "    names += top_names[countries]['F']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da5a84ca-c752-4ae7-b6f9-f8cdf01ec7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nd = NameDataset()\n",
    "#names = nd.get_top_names(country_alpha2='AT')['AT']\n",
    "#names = names['M'] + names['F']\n",
    "# train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0a71f53-7b2a-42da-8872-1113160e31c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, dataloader, model, loss_func, optimizer, scaler, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "    loss_ls = []\n",
    "    n_samples = 0\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        batch = batch.to(device)\n",
    "        bs = batch.shape[0]\n",
    "        n_samples += bs\n",
    "        model.zero_grad()\n",
    "        \n",
    "        with torch.cuda.amp.autocast():\n",
    "            out = model(batch)\n",
    "        \n",
    "        # note: we need to compare the t'th output with the (t+1)'th token in our batch!\n",
    "        # loss = loss_func(out[:,:-1].reshape(-1, model.config.dict_size), batch[:,1:].reshape(-1))\n",
    "        loss = loss_func(out[:,:-1].reshape(-1, model.config.dict_size), batch[:,1:].reshape(-1))\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "    return loss.item()/bs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "302cae72-7f43-4aef-af00-3d9b507414f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(epoch, dataloader, model, loss_func, device='cpu'):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    val_loss = []\n",
    "    \n",
    "    n_samples = 0\n",
    "    loss_sum = 0\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(dataloader):\n",
    "            batch = batch.to(device)\n",
    "            out = model(batch)\n",
    "            loss = loss_func(out[:,:-1].reshape(-1, model.config.dict_size), batch[:,1:].reshape(-1))\n",
    "            #print(f'val loss: {loss}')\n",
    "            loss_sum += loss.item()\n",
    "            n_samples += batch.shape[0]\n",
    "            #print(n_samples)\n",
    "    avg_loss = loss_sum/n_samples\n",
    "    return avg_loss                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be95625-a0d4-474f-b4cd-b7e07d713e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(n_epochs=20):\n",
    "    \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    \n",
    "    seq_len = 50\n",
    "\n",
    "    # create split\n",
    "    train_split, val_split = split_data(names, 0.75)\n",
    "\n",
    "    # create datasets\n",
    "    train_data = NamesDs(train_split, seq_len)\n",
    "    val_data = NamesDs(val_split, seq_len)\n",
    "\n",
    "    # create loader\n",
    "    train_loader = DataLoader(train_data, batch_size=256, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_data, batch_size=266, shuffle=False, num_workers=4)\n",
    "    \n",
    "    # create loss\n",
    "    loss_fun = nn.CrossEntropyLoss(ignore_index=train_data.get_padding_token(), size_average=True)\n",
    "    \n",
    "    # instantiate model\n",
    "    dict_size = train_data.num_letters()\n",
    "    config = Config(dict_size=dict_size, \n",
    "                    out_dim=dict_size, \n",
    "                    d=128, \n",
    "                    input_dim=128, \n",
    "                    conditional=True)\n",
    "    model = ManyToManyTransformer(config)\n",
    "    \n",
    "    # we use mixed precission\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    # optimizer\n",
    "    # optim = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr=0.001)\n",
    "    \n",
    "    epochs = n_epochs\n",
    "    \n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    for epoch in range(epochs):\n",
    "        t_loss = train(epoch, train_loader, model, loss_fun, optim, scaler=scaler, device=device)\n",
    "        v_loss = val(epoch, val_loader, model, loss_fun, device=device)\n",
    "        print(f\"\\repoch: [{epoch}/{n_epochs}]: train_loss = {t_loss:.5f} | val_loss = {v_loss:.5f}\", end=\"\")\n",
    "        train_loss.append(t_loss)\n",
    "        val_loss.append(v_loss)\n",
    "    return model, train_loss, val_loss, train_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6f232feb-bb9a-4e62-bfcb-d78714ec368c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "next(model.parameters()).is_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2e442ed8-0ab1-4571-a880-a952c295ff12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: [2/50]: train_loss = 0.02061 | val_loss = 0.04851"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: [49/50]: train_loss = nan | val_loss = nan 0.05636"
     ]
    }
   ],
   "source": [
    "\n",
    "model, train_loss, val_loss, train_data, val_data = main(n_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6d2863-46f3-4f1a-9c88-ce8159614df6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b5809a8-76b9-4c5b-b5a2-8c0248b92ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_loss, label='train loss')\n",
    "plt.plot(val_loss, label='val loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "92b8f1f8-1fa9-4516-a084-2428075da6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'arnnishelapadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpad'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cpu')\n",
    "out = model.generate(bos_idx=train_data.get_start_token(),\n",
    "                     eos_idx=train_data.get_end_token(),\n",
    "                     pad_idx=train_data.get_padding_token(),\n",
    "                     from_top_k=5)\n",
    "train_data.idx2name(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "58949c2e-0e84-4a6e-beaa-74036da1e917",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11976/2442032038.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_data.idx2name(torch.tensor(out))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'jumalildsayopadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpadpad'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_str = 'ju'\n",
    "s = train_data.name2idx(input_str)[:len(input_str)+1]\n",
    "print(len(s))\n",
    "out = model.generate(bos_idx=train_data.get_start_token(), \n",
    "                     eos_idx=train_data.get_end_token(),\n",
    "                     pad_idx=train_data.get_padding_token(),\n",
    "                     start_idx=s, from_top_k=5)\n",
    "train_data.idx2name(torch.tensor(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f730691c-e2ec-478b-97e8-c0315ee247dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
